{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip 2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-f96e526d6f5b>\", line 6, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 959, in _find_and_load_unlocked\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 52, in <module>\n",
      "    from tensorflow.core.framework.graph_pb2 import *\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 7, in <module>\n",
      "    from google.protobuf import descriptor as _descriptor\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/google/protobuf/__init__.py\", line 37, in <module>\n",
      "    __import__('pkg_resources').declare_namespace(__name__)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 3251, in <module>\n",
      "    @_call_aside\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 3235, in _call_aside\n",
      "    f(*args, **kwargs)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 3264, in _initialize_master_working_set\n",
      "    working_set = WorkingSet._build_master()\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 574, in _build_master\n",
      "    ws = cls()\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 567, in __init__\n",
      "    self.add_entry(entry)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 623, in add_entry\n",
      "    for dist in find_distributions(entry, True):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2065, in find_on_path\n",
      "    for dist in factory(fullpath):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2127, in distributions_from_metadata\n",
      "    if len(os.listdir(path)) == 0:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 11, in <module>\n",
      "    from tensorflow.python.eager import context as _context\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\", line 32, in <module>\n",
      "    from tensorflow.python import tf2\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 140, in <module>\n",
      "    from tensorflow.python.eager.context import executing_eagerly\n",
      "ImportError: cannot import name 'executing_eagerly' from 'tensorflow.python.eager.context' (/home/khanh/miniconda3/envs/cs_ftmle/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import preprocess as prep\n",
    "import h5py\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imutils\n",
    "# import mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT ='/home/khanh/Coderschool/week8/weekly-project/data/raw'\n",
    "TRAIN_DIR = os.path.join(ROOT, '0916_Data Samples 2')\n",
    "TEST_DIR = os.path.join(ROOT, '0825_DataSamples 1')\n",
    "TRAIN_PRE = os.path.join('/home/khanh/Coderschool/week8/weekly-project/data/data', 'Train')\n",
    "TEST_PRE = os.path.join('/home/khanh/Coderschool/week8/weekly-project/data/data', 'Test')\n",
    "# os.mkdir(TRAIN_DIR)\n",
    "# os.mkdir(TEST_DIR)\n",
    "print(TRAIN_DIR)\n",
    "TRAIN_PRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(TRAIN_DIR, '')\n",
    "all_file_path = path.glob('**/*')\n",
    "all_file_path = list(all_file_path)\n",
    "all_file_path = [str(path) for path in all_file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ipynb_folder_if_exists(folder):\n",
    "    folder = pathlib.Path(folder)\n",
    "    ipynb_paths = [str(item) for item in folder.glob('**/*') if item.is_dir() and item.name.startswith('.ipynb')]\n",
    "    if len(ipynb_paths) > 0:\n",
    "        for eachdir in ipynb_paths:\n",
    "            shutil.rmtree(eachdir)\n",
    "            print(\"Removed\", eachdir)\n",
    "    else:\n",
    "        print('No .ipynb_checkpoints to remove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(folder_path):\n",
    "    path = pathlib.Path(folder_path, '')\n",
    "\n",
    "    all_file_path = path.glob('**/*')\n",
    "    all_file_path = list(all_file_path)\n",
    "    all_file_path = [str(path) for path in all_file_path]\n",
    "    all_file_path = [m for m in all_file_path if m.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    clean_ipynb_folder_if_exists(folder_path)\n",
    "    \n",
    "    return all_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_file_path = [path for path in all_file_path if os.path.isfile(path)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove any file is not image\n",
    "all_file_path = [m for m in all_file_path if m.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(len(all_file_path))\n",
    "all_file_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(all_file_path_new))\n",
    "# for i in all_file_path:\n",
    "#     if i not in all_file_path_new:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing processing img with only one img for saving time\n",
    "# import random\n",
    "# random.seed(42)\n",
    "\n",
    "# test_image = random.choice(all_file_path)\n",
    "# test_image\n",
    "\n",
    "# # shutil.copy(test_image, str(TRAIN_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(type_):\n",
    "    ''' Build tf dataset form already repreocessing file'''\n",
    "    data_path = os.path.join('.', 'Data', '{}.hdf5'.format(type_))\n",
    "    dataset = dict()\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        dataset['image'] = f['image'][:]\n",
    "        dataset['label'] = f['label'][:]\n",
    "        \n",
    "        size = len(dataset['label'])\n",
    "        dataset['label'] = [x.decode() for x in dataset['label']]\n",
    "        \n",
    "        return dataset, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(folder_path):\n",
    "    labels = json.load(open(os.path.join(folder_path, 'labels.json')))\n",
    "    return labels\n",
    "\n",
    "# lables = json.load(open(os.path.join('.', 'Data', '{}.json'.format('labels'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_label(all_file_path, all_labels):\n",
    "    remove_path = []\n",
    "    for i in all_file_path:\n",
    "        key = i.split('/')[-1]\n",
    "        if key not in all_labels:\n",
    "            remove_path.append(i)\n",
    "            for i in remove_path:\n",
    "                all_file_path.remove(i)\n",
    "    \n",
    "    return all_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(folder_path):\n",
    "    all_img_labels = []\n",
    "    all_labels = load_label(folder_path)\n",
    "    all_file_path = get_path(folder_path)\n",
    "    for i in all_file_path:\n",
    "        key = i.split('/')[-1]\n",
    "        if key in all_labels:\n",
    "            all_img_labels.append(all_labels[key])\n",
    "    \n",
    "    return all_img_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelling(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "test_imge = random.choice(all_file_path)\n",
    "image = cv2.imread(test_imge)           \n",
    "plt.imshow(image)\n",
    "plt.show\n",
    "\n",
    "# r = image.shape[1] // image.shape[0]\n",
    "# dim = (500*r, 500)\n",
    "# resize = cv2.resize(image, dim)\n",
    "# print(resize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(new_folder, old_folder):\n",
    "    res = []\n",
    "    new_label = get_label_from_dir(new_folder, old_folder)\n",
    "    for label in new_label:\n",
    "        for word in label:\n",
    "            if word not in res:\n",
    "                res.append(word)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt = get_label_from_dir(TEST_PRE, TEST_DIR).values()\n",
    "print(list(val_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenize(TEST_DIR)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_res = []\n",
    "\n",
    "# for label in test_label:\n",
    "#     for word in label:\n",
    "#         if word not in test_res:\n",
    "#             test_res.append(word)\n",
    "\n",
    "# test_char = ''.join(sorted(test_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charset(train_dir, test_dir):\n",
    "\n",
    "    train_res = tokenize(train_dir)\n",
    "    test_res = tokenize(test_dir)\n",
    "  \n",
    "    for i in test_res:\n",
    "        if i not in train_res:\n",
    "            train_res.append(i)\n",
    "\n",
    "    charset = ''.join(sorted(train_res))  \n",
    "    return charset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(charset(TRAIN_DIR, TEST_DIR)), charset(TRAIN_DIR, TEST_DIR)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '#()+,-./:0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnopqrstwuvxyzÂÊÔàáâãèéêẹìíòóôõùúýăĐđĩũƠơưạảấầẩẫậắằẵặẻẽếềểễệỉịọỏốồổỗộớờởỡợụủỨứừửữựỳỵỷỹ'\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train_dir, test_dir):  \n",
    "    res = []\n",
    "    \n",
    "    char = charset(TRAIN_DIR, TEST_DIR)\n",
    "    char2text = {values: key for key, values in enumerate(char)}\n",
    "    train_labels = labelling(TRAIN_DIR)\n",
    "    test_labels = labelling(TEST_DIR)\n",
    "    train_labels.extend(test_labels)\n",
    "    text = [i for i in train_labels]\n",
    "    for line in text:\n",
    "        for word in line:\n",
    "            encode = char2text.get(word)\n",
    "            res.append(encode)\n",
    " \n",
    "    return np.asarray(res, dtype=np.int32)\n",
    "\n",
    "def decode(text_encode):\n",
    "    decode = ''.join([char_array[x] for x in text_encode])\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train_dir, test_dir):  \n",
    "    res = []\n",
    "    \n",
    "    char = charset(TRAIN_DIR, TEST_DIR)\n",
    "    char2text = {values: key for key, values in enumerate(char)}\n",
    "    train_labels = labelling(TRAIN_DIR)\n",
    "    test_labels = labelling(TEST_DIR)\n",
    "    train_labels.extend(test_labels)\n",
    "    text = [i for i in train_labels]\n",
    "    for line in text:\n",
    "        for word in line:\n",
    "            encode = char2text.get(word)\n",
    "            res.append(encode)\n",
    " \n",
    "    return np.asarray(res, dtype=np.int32)\n",
    "\n",
    "def decode(text_encode):\n",
    "    decode = ''.join([char_array[x] for x in text_encode])\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encode(TRAIN_DIR, TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in all_img_labels:\n",
    "#     for word in i:\n",
    "#         encode = char2text.get(word)\n",
    "#         print(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_first(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (11,11), 0)\n",
    "    edged = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 5)\n",
    "    edged = cv2.resize(edged, dsize=(1900, 120))\n",
    "    return edged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = get_path(TRAIN_DIR)\n",
    "img = preprocess_first(img_path[0])\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max = (0, 0)\n",
    "# for i in all_file_path:\n",
    "#     test = cv2.imread(i)\n",
    "#     if test.shape > max:\n",
    "#         max = test.shape\n",
    "\n",
    "# print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NEW = './Data/Train'\n",
    "VAL = './Data/Test'\n",
    "# for i in all_file_path:\n",
    "#     filename = i.split('/')[-1]\n",
    "#     path = os.path.join(TRAIN_NEW, filename)\n",
    "#     image = preprocess(i)\n",
    "#     image = remove_cursive_style(image)\n",
    "#     cv2.imwrite(path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from generator import get_path\n",
    "# def load_img(folder_path, save_path):\n",
    "#     all_file_path = get_path(folder_path)\n",
    "#     for i in all_file_path:\n",
    "#         filename = i.split('/')[-1]\n",
    "#         path = os.path.join(save_path, filename)\n",
    "#         image = preprocess_first(i)\n",
    "#         cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(folder_path, save_path):\n",
    "    all_file_path = get_path(folder_path)\n",
    "    for i in all_file_path:\n",
    "        filename = i.split('/')[-1]\n",
    "        path = os.path.join(save_path, filename)\n",
    "        image = preprocess_first(i)\n",
    "        cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = load_img(TEST_DIR, TEST_PRE)\n",
    "# len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(TRAIN_NEW, '')\n",
    "\n",
    "all_file_path = path.glob('*.png')\n",
    "all_file_path = list(all_file_path)\n",
    "all_file_path = [str(path) for path in list(all_file_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = len(all_file_path)\n",
    "ratio = 0.1\n",
    "len_train = int(len_data * (1- ratio))\n",
    "len_val = len_data - len_train\n",
    "print(len_train, len_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf Data/Test/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# train_path = all_file_path[:len_train]\n",
    "# val_path = all_file_path[len_train:]\n",
    "\n",
    "# for i in val_path:\n",
    "#     shutil.move(i, VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = pathlib.Path(TRAIN_NEW)\n",
    "# train_path = train_path.glob('**/*')\n",
    "# train_path = [str(i) for i in train_path]\n",
    "# len(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_path = pathlib.Path(VAL)\n",
    "# val_path = val_path.glob('**/*')\n",
    "# val_path = [str(i) for i in val_path]\n",
    "# len(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ipynb_folder_if_exists(TRAIN_NEW)\n",
    "clean_ipynb_folder_if_exists(VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label = []\n",
    "# val_label = []\n",
    "\n",
    "# for i in train_path:\n",
    "#     label = (i.split('/'))[-1]\n",
    "#     label = all_labels[label]\n",
    "#     train_label.append(label)\n",
    "    \n",
    "# for i in val_path:\n",
    "#     label = (i.split('/'))[-1]\n",
    "#     label = all_labels[label]\n",
    "#     val_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_path(TEST_PRE)\n",
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_dir(new_folder, old_folder):\n",
    "    path_img = get_path(new_folder)\n",
    "    old_label = load_label(old_folder)\n",
    "    new_label = {}\n",
    "    for i in path_img:\n",
    "        label = (i.split('/'))[-1]\n",
    "        label = old_label[label]\n",
    "        new_label[i.split('/')[-1]] = label\n",
    "    \n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_from_dir(TEST_PRE, TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_path(path):\n",
    "    label = (path.split('/'))[-1]\n",
    "    label = all_labels[label]\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "    image = image[:,:,1]\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "    return np.array(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_for_model(new_folder, old_folder):\n",
    "    all_path = get_path(new_folder)\n",
    "    all_label = get_label_from_dir(new_folder, old_folder)\n",
    "    label_list = []\n",
    "    image_list = []\n",
    "    \n",
    "    for path in all_path:\n",
    "        label = (path.split('/'))[-1]\n",
    "        label = all_label[label]\n",
    "        label_list.append(label)\n",
    "        \n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "    #     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #     image = tf.image.per_image_standardization(image)\n",
    "        image = image[:,:,1]\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        image_list.append(np.array(image))\n",
    "    \n",
    "    return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_path = get_path(TEST_DIR)\n",
    "# all_label = get_label_from_dir(TEST_PRE, TEST_DIR)\n",
    "\n",
    "# for path in all_path[:5]:\n",
    "#     print(path)\n",
    "#     label = (path.split('/'))[-1]\n",
    "#     print(label)\n",
    "#     label = all_label[label]\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = pre_for_model(TEST_PRE, TEST_DIR)\n",
    "print(b[0], a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_count = len(train_label)\n",
    "# val_count = len(val_label)\n",
    "\n",
    "# BATCH_SIZE = 64\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# def create_ds(images, labels, count):\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "#     ds = ds.repeat()\n",
    "#     ds = ds.batch(BATCH_SIZE)\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "#     return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_img = []\n",
    "# for i in TRAIN_PRE:\n",
    "#     image =  preprocess_path(i)[0]\n",
    "#     training_img.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_len = []\n",
    "train_txt = []\n",
    "\n",
    "\n",
    "for i in train_label:\n",
    "    text_encode = encode(i)\n",
    "    train_txt.append(list(text_encode))\n",
    "    train_label_len.append(len(text_encode))\n",
    "\n",
    "len(train_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_img = []\n",
    "for i in val_path:\n",
    "    image =  preprocess_path(i)[0]\n",
    "    valid_img.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_img[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_label_len = []\n",
    "valid_txt =[]\n",
    "\n",
    "for i in val_label:\n",
    "    text_encode = encode(i)\n",
    "    valid_txt.append(list(text_encode))\n",
    "    valid_label_len.append(len(text_encode))\n",
    "\n",
    "max(valid_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our model, different layers and activation function \n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUR FULL MODEL OF CRNN AND LSTM\n",
    "\n",
    "# YOUR PART: TRY TO BUILD YOUR DIFFERENT TIMESTEPS AND BUILD TO DO IT, LET SAY 26 OR 32 INSTEAD OF 31 LIKE BELOW. \n",
    "def build_model(train_dir, test_dir):\n",
    "    # input with shape of height=118 and width=1875 \n",
    "    inputs = Input(shape=(120,1900,1))   # (118,1875,3)\n",
    "\n",
    "    # convolution layer with kernel size (3,3)\n",
    "    conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)  # (120,1900,64)\n",
    "\n",
    "    # poolig layer with kernel size (2,2) to make the height/2 and width/2  # (60,950,64)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)  # (60,950,128)\n",
    "\n",
    "    # poolig layer with kernel size (2,2) to make the height/2 and width/2   # (30,475,128)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)   # (30,475,256)\n",
    "\n",
    "    conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)   # (30,475,256)\n",
    "\n",
    "    # poolig layer with kernel size (2,2) to make the height/2              # (15,95,256)\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 5))(conv_4)\n",
    "\n",
    "    conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)  # (15,95,512)\n",
    "\n",
    "    # Batch normalization layer\n",
    "    batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "    conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)  # (15,95,512)\n",
    "    batch_norm_6 = BatchNormalization()(conv_6)\n",
    "\n",
    "    # poolig layer with kernel size (2,2) to make the height/2       # (15,95,512)\n",
    "    pool_6 = MaxPool2D(pool_size=(5, 1))(batch_norm_6)\n",
    "\n",
    "    # didn't have padding = \"same\" to reduce timestep - 1 because kernel size is # (1,95,512)\n",
    "    conv_7 = Conv2D(512, (3,1), activation = 'relu')(pool_6)\n",
    "\n",
    "    # to remove the first dimension of one: (1, 95, 512) to (95, 512) \n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "\n",
    "    # bidirectional LSTM layers with units=95\n",
    "    blstm_1 = Bidirectional(LSTM(95, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "    blstm_2 = Bidirectional(LSTM(95, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    "\n",
    "    # this is our softmax character proprobility with timesteps (31, 63)\n",
    "    outputs = Dense(len(charset(train_dir, test_dir))+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "    # model to be used at test time\n",
    "\n",
    "    act_model = Model(inputs, outputs)\n",
    "    return (act_model, outputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    \"\"\"\n",
    "    labels: tensor (number of samples, max_string_length) containing the truth labels.\n",
    "    y_pred: tensor (number of samples, time_steps, num_character_labels) containing the prediction, or output of the softmax.\n",
    "    input_length: tensor (number of samples, 1) containing the sequence length for each batch item in y_pred.\n",
    "    label_length: tensor (number of samples, 1) containing the sequence length for each batch item in y_true.\n",
    "    \"\"\"\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc_layer(outputs, inputs):\n",
    "    max_label_len = 70\n",
    "\n",
    "    # define the label input shape for ctc\n",
    "    labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "\n",
    "    # define a ctc lambda function to take arguments and return ctc_bach_cost\n",
    "    # define the length of input and label for ctc\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # out loss function (just take the inputs and put it in our ctc_batch_cost)\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "    #model to be used at training time\n",
    "    model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, outputs, inputs = build_model(TRAIN_DIR, TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctc_layer(outputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready ctc loss function and optimizersval\n",
    "\n",
    "\n",
    "# ready out check point save file\n",
    "def define_checkpoint(checkpoint_name):\n",
    "    filepath=checkpoint_name\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "    callbacks_list = [checkpoint]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = define_checkpoint(\"Khanh.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(sequence):\n",
    "    MAXLEN = 70\n",
    "    sequence = list(sequence)\n",
    "    sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=MAXLEN, padding='post')\n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_txt = get_label_from_dir(TEST_PRE, TEST_DIR).values()\n",
    "valid_txt = list(valid_txt)\n",
    "char = charset(TRAIN_DIR, TEST_DIR)\n",
    "# def get_image(folder_path):\n",
    "#     img_list = []\n",
    "#     path = get_path(folder_path)\n",
    "#     for i in path:\n",
    "#         image =  preprocess_path(i)\n",
    "#         img_list.append(image)\n",
    "    \n",
    "#     return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready our training data\n",
    "training_img = pre_for_model(TRAIN_PRE, TRAIN_DIR)\n",
    "train_padded_txt = pad(train_txt)\n",
    "train_input_len = np.ones(len(training_img))*95  # must be equal length to T timesteps = 95\n",
    "train_label_len = np.array(train_label_len)  # different length\n",
    "\n",
    "\n",
    "# ready our test data\n",
    "valid_img = pre_for_model(TEST_PRE, TEST_DIR)\n",
    "valid_padded_txt = pad(valid_txt)\n",
    "valid_input_len = np.ones(len(valid_img))*95 # must be equal length to T timesteps = 95\n",
    "valid_label_len = np.array(valid_label_len) # different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose batchsize and epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x=[training_img, train_padded_txt, train_input_len, train_label_len], \n",
    "          y=np.zeros(len(training_img)), \n",
    "          batch_size=batch_size, \n",
    "          epochs = epochs, \n",
    "          validation_data = ([valid_img, valid_padded_txt, valid_input_len, valid_label_len], [np.zeros(len(valid_img))]), \n",
    "          verbose = 1, \n",
    "          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our model\n",
    "# model.save('Khanh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved best model weights\n",
    "act_model.load_weights('Khanh.hdf5')\n",
    "\n",
    "# predict outputs on validation images\n",
    "prediction = act_model.predict(valid_img[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decoder(prediction, val_label, charset):\n",
    "    # use CTC decoder\n",
    "    out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                             greedy=True)[0][0])\n",
    "\n",
    "    # see the results\n",
    "    i = 0\n",
    "    for x in out:\n",
    "        print(\"original_text =  \", val_label[i])\n",
    "        print(\"predicted text = \", end = '')\n",
    "        for p in x:  \n",
    "            if int(p) != -1:\n",
    "                print(charset[int(p)], end = '')       \n",
    "        print('\\n')\n",
    "        i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
